# ðŸ” LinkedIn Career Recommender

This project helps LinkedIn users discover *relevant companies, **job opportunities, and **online courses* based on their most recent position. The system is built from three *independent* Jupyter notebooks, each focusing on a different stage of the recommendation pipeline.

---

## ðŸ‘¨â€ðŸ’» Team Members
Yechezkel Nikop
Itzhak Danan
refael Levi

---

## ðŸ“ Project Structure

> ðŸ’¡ *Each part is independent and can be executed separately.*

### â¿¡ project_yechezkel_part_1.ipynb â€“ Company Matching
Finds companies that are relevant to a user's latest job, based on industry, company type, and size.  
Built using PySpark to process LinkedIn company and user data.

- âŒ *This notebook does not include a runnable example.*
- ðŸ›  You may add a test profile manually to simulate the process.

---

### â¿¢ project_itzik_part_2.ipynb â€“ Job Recommendation
Ranks job postings from the matched companies using multiple criteria:
- Semantic similarity (BERT-based cosine similarity between profile and job)
- Geographic proximity (via geopy)
- Salary normalization
- Job type weighting

- âœ… *Includes a complete demo run at the end of the notebook.*

---

### â¿£ project_refael_part_3.ipynb â€“ Course Recommendation
Recommends online courses based on job descriptions using a dataset of thousands of training programs.

- âœ… *Includes a demo run at the end of the notebook.*

---

## âš™ How to Run

Each notebook runs independently and can be executed in Jupyter or Google Colab.

### Installation
Install the required Python packages:

```bash
pip install pandas numpy scikit-learn transformers geopy torchÂ matplotlib

---

## ðŸ“‚ Data Access

The processed data files used in this project are available at the following secure location:

ðŸ”— [Private Google Drive Link](https://drive.google.com/your_link_here)

> âš  Original LinkedIn / BrightData raw datasets are *not* included in the repository, in accordance with theÂ projectÂ policy.

---

### ðŸ•¸ project_scraping.ipynb â€“ Scraping Module  
This notebook contains the code used to collect online course data using automated web scraping. The scraping was performed via *Bright Data proxies*, enabling access to course platforms such as Coursera and Udemy as part of the data collectionÂ process.
