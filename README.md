# ğŸ” LinkedIn Career Recommender

This project helps LinkedIn users discover *relevant companies, **job opportunities, and **online courses* based on their most recent position. The system is built from *three independent modules*, supported by a web scraping component for course data collection.

---

## ğŸ‘¨â€ğŸ’» Team Members
- Yitzhak Danan 
- Yechezkel Nikop
- Rafael Levi

---

## ğŸ“ Project Structure

> ğŸ’¡ *Each notebook is independent and can be executed on its own.*

### â¿¡ project_yechezkel_part_1.ipynb â€“ Company Matching  
Receives the user's most recent company and returns three similar companies using a classification model based on TF-IDF of company descriptions, size, and number of followers.  
All data processing was done using *Apache Spark, similar to **Homework 3* in the course.  
- âŒ No demo included (can be added manually if needed)

### â¿¢ project_itzik_part_2.ipynb â€“ Job Recommendation  
Ranks job openings from matched companies using BERT-based semantic similarity, location proximity, salary normalization, and job type weighting.  
- âœ… Includes a complete demo run at the end

### â¿£ project_refael_part_3.ipynb â€“ Course Recommendation  
Recommends relevant online courses for each job based on job descriptions.  
- âœ… Includes a demo run at the end

### ğŸ•¸ project_scraping.ipynb â€“ Scraping Module  
Contains the scraping logic used to collect online course data (e.g., from Coursera and Udemy).  
The scraping was done using *Bright Data proxies* to bypass site limitations and ensure access to real-time course listings.

> âš  *Note:* The scraped course data is *not included* in the repository due to data usage restrictions.

---

## ğŸ“‚ Data Access

The repository does *not* contain any raw data from LinkedIn or Bright Data, in accordance with course regulations and data usage policies.

However, the following *processed and publicly available datasets* are shared for demonstration purposes:

1. courses.pkl â€“ A filtered and cleaned dataset of online courses collected via web scraping using Bright Data proxies.  
   âœ… Includes only high-level metadata (title, description, rating, etc.), no raw HTML or platform-specific identifiers.

2. linkedin_124k_kaggle_filterd.csv â€“ A public job listing dataset downloaded from Kaggle and filtered to include relevant job postings for testing the recommendation system.

These files are hosted in a private folder accessible here:  
ğŸ”— [https://drive.google.com/drive/folders/1OnR9EMFlNNsNN3u2Hl7QEkor_m_Q8sGV?usp=drive_link]

> âœ… Access permission should be set to: *"Anyone with the link can view"*  
> âŒ Do not include any raw LinkedIn or Bright Data files in the repository or in this folder.

---
## ğŸ“¢ Project Video Demonstration

we created a short video presenting the project and explaining its components.

ğŸ”— [ğŸ¬ Watch the demo video][https://drive.google.com/drive/folders/1ZnQMmPHOd507nDV-H_7NN7YzFmiRJQHa?usp=drive_link]

## âš™ How to Run

Each notebook can be run separately in Jupyter or Google Colab.  
Please make sure the required dependencies are installed.

### Installation:
```bash
pip install pandas numpy scikit-learn transformers geopy torchÂ matplotlib



